## Getting Started

<span id="getting-started" />

### Installation

<span id="installation" />

```bash
pip install corp-extractor
```

The spaCy model for predicate inference is downloaded automatically on first use.

**GPU support**: Install PyTorch with CUDA before installing corp-extractor. The library auto-detects GPU availability at runtime.

```bash
# Example for CUDA 12.1
pip install torch --index-url https://download.pytorch.org/whl/cu121
pip install corp-extractor
```

**Apple Silicon (M1/M2/M3)**: MPS acceleration is automatically detected. Just install normally:

```bash
pip install corp-extractor
```

### Quick Start

<span id="quick-start" />

Extract structured statements from text in 5 lines:

```python
from statement_extractor import extract_statements

text = "Apple Inc. acquired Beats Electronics for $3 billion in May 2014."
statements = extract_statements(text)

for stmt in statements:
    print(f"{stmt.subject.text} ({stmt.subject.entity_type}) -> {stmt.predicate} -> {stmt.object.text}")
```

Output:

```
Apple Inc. (ORG) -> acquired -> Beats Electronics
Apple Inc. (ORG) -> paid -> $3 billion
Beats Electronics (ORG) -> acquisition price -> $3 billion
```

Each statement includes confidence scores (v0.2.0+):

```python
for stmt in statements:
    print(f"{stmt.subject.text} -> {stmt.predicate} -> {stmt.object.text}")
    print(f"  confidence: {stmt.confidence:.2f}")
```

v0.2.0 features: confidence scoring, batch processing, embedding support, and improved entity type detection.

### Using Predicate Taxonomies

Normalize extracted predicates to canonical forms using embedding similarity:

```python
from statement_extractor import extract_statements, PredicateTaxonomy, ExtractionOptions

# Define your domain's canonical predicates
taxonomy = PredicateTaxonomy(predicates=[
    "acquired", "founded", "works_for", "headquartered_in",
    "invested_in", "partnered_with", "announced"
])

options = ExtractionOptions(predicate_taxonomy=taxonomy)

text = "Google bought YouTube for $1.65 billion in 2006."
result = extract_statements(text, options)

for stmt in result:
    print(f"{stmt.predicate} -> {stmt.canonical_predicate}")
    # Output: bought -> acquired
```

This maps synonyms like "bought", "purchased", "acquired" to a single canonical form, making downstream analysis easier.

### Requirements

<span id="requirements" />

<table>
  <thead>
    <tr>
      <th>Dependency</th>
      <th>Version</th>
      <th>Notes</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Python</td>
      <td>3.10+</td>
      <td>Required</td>
    </tr>
    <tr>
      <td>PyTorch</td>
      <td>2.0+</td>
      <td>Required</td>
    </tr>
    <tr>
      <td>transformers</td>
      <td>5.0+</td>
      <td>Required for T5-Gemma2 support</td>
    </tr>
    <tr>
      <td>Pydantic</td>
      <td>2.0+</td>
      <td>Required</td>
    </tr>
    <tr>
      <td>sentence-transformers</td>
      <td>2.2+</td>
      <td>Required, for embedding features</td>
    </tr>
    <tr>
      <td>spaCy</td>
      <td>3.5+</td>
      <td>Required, for predicate inference (model auto-downloads)</td>
    </tr>
  </tbody>
</table>

**Hardware requirements**:

- **NVIDIA GPU**: ~2GB VRAM minimum. CUDA-enabled GPU recommended for production.
- **Apple Silicon**: M1/M2/M3 Macs with MPS acceleration. Good performance, auto-detected.
- **CPU**: ~4GB RAM. Functional but significantly slower. Use for development or low-volume processing.

The model uses bfloat16 precision on CUDA (faster, less memory) and float32 on MPS/CPU.
