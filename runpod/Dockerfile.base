# Base image with PyTorch 2.6.0 for Statement Extractor
# Build once: docker build -f Dockerfile.base -t neilellis/pytorch-base:2.6.0-cu124 --platform linux/amd64 .
FROM runpod/pytorch:2.4.0-py3.11-cuda12.4.1-devel-ubuntu22.04

WORKDIR /app

# Upgrade PyTorch to 2.6+ (required for T5Gemma2 masking_utils)
RUN pip install --no-cache-dir --upgrade \
    torch==2.6.0 \
    torchvision \
    torchaudio \
    --index-url https://download.pytorch.org/whl/cu124

# Install llama-cpp-python with CUDA support (slow to compile)
ENV CMAKE_ARGS="-DGGML_CUDA=on"
RUN pip install --no-cache-dir llama-cpp-python